{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_data_dir = \"/data/cb/scratch/datasets/atlas\"\n",
    "atlas_dynamicslabels_dir = \"/data/cb/scratch/datasets/atlas_dynamics_labels\"\n",
    "config_dir = \"../trained/configs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aatype: torch.Size([10, 512, 21])\n",
      "residue_index: torch.Size([10, 512])\n",
      "all_atom_positions: torch.Size([10, 512, 37, 3])\n",
      "all_atom_mask: torch.Size([10, 512, 37])\n",
      "resi_pad_mask: torch.Size([10, 512])\n",
      "dynamics_means: torch.Size([10, 512, 3])\n",
      "dynamics_covars: torch.Size([10, 512, 3, 3])\n",
      "frames: torch.Size([10, 512, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Load data config\n",
    "with open(config_dir+\"/data/atlas_config.yaml\", \"r\") as file:\n",
    "    dataconfig = yaml.safe_load(file)\n",
    "    \n",
    "# Load train config\n",
    "with open(config_dir+\"/model/dynaprot_simple.yaml\", \"r\") as file:\n",
    "    modelconfig = yaml.safe_load(file)\n",
    "    \n",
    "modelconfig[\"data_config\"] = dataconfig\n",
    "    \n",
    "from DynaProt.data.datasets import DynaProtDataset, OpenFoldBatchCollator\n",
    "\n",
    "dataset = DynaProtDataset(dataconfig)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=10,\n",
    "        collate_fn=OpenFoldBatchCollator(),\n",
    "        num_workers=12,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "batch_prots = next(iter(dataloader))\n",
    "\n",
    "for k in batch_prots.keys():\n",
    "    # print(k,batch_prots[k])\n",
    "    print(f\"{k}: {batch_prots[k].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynaProt(\n",
       "  (sequence_embedding): Embedding(21, 128)\n",
       "  (ipa_blocks): ModuleList(\n",
       "    (0-7): 8 x InvariantPointAttention(\n",
       "      (linear_q): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (linear_kv): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear_q_points): Linear(in_features=128, out_features=48, bias=True)\n",
       "      (linear_kv_points): Linear(in_features=128, out_features=144, bias=True)\n",
       "      (linear_b): Linear(in_features=128, out_features=4, bias=True)\n",
       "      (linear_out): Linear(in_features=704, out_features=128, bias=True)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "      (softplus): Softplus(beta=1.0, threshold=20.0)\n",
       "    )\n",
       "  )\n",
       "  (mean_predictor): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (covars_predictor): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DynaProt.model.DynaProt import DynaProt\n",
    "\n",
    "model = DynaProt(modelconfig)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_prots\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/cb/mihirb14/projects/dynaprot/experiments/../DynaProt/model/DynaProt.py:86\u001b[0m, in \u001b[0;36mDynaProt.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m predicted_means, predicted_covars \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m],preds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovars\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     85\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(predicted_means, true_means)\n\u001b[0;32m---> 86\u001b[0m covars_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_divergence_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_means\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_covars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_means\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_covars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m mean_loss \u001b[38;5;241m+\u001b[39m covars_loss\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Log the loss and return\u001b[39;00m\n",
      "File \u001b[0;32m/data/cb/mihirb14/projects/dynaprot/experiments/../DynaProt/model/DynaProt.py:98\u001b[0m, in \u001b[0;36mDynaProt.kl_divergence_loss\u001b[0;34m(self, pred_means, pred_vars, true_means, true_vars)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkl_divergence_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, pred_means, pred_vars, true_means, true_vars):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# KL Divergence between two Gaussian distributions\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# pred_means, pred_vars are predicted, true_means, true_vars are ground truth\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     kl_loss \u001b[38;5;241m=\u001b[39m (true_vars \u001b[38;5;241m/\u001b[39m pred_vars)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mpred_means\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrue_means\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpred_vars\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     99\u001b[0m     kl_loss \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_residues  \u001b[38;5;66;03m# Adjustment for dimensions\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     kl_loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "model.training_step(batch_prots,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]],\n",
      "\n",
      "         [[ 1.7247,  2.6265,  3.9398],\n",
      "          [ 2.6265, 20.1455, 26.0907],\n",
      "          [ 3.9398, 26.0907, 70.0297]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "b = 10\n",
    "n = 2\n",
    "preds = torch.repeat_interleave(torch.arange(6)+1,n).reshape(-1,n).T.unsqueeze(0).repeat(b,1,1)\n",
    "# print(preds,preds.shape)\n",
    "\n",
    "\n",
    "L = torch.zeros(b,n,3,3)\n",
    "\n",
    "i = 0\n",
    "for c in range(3):\n",
    "    for r in range(c,3):\n",
    "        L[:,:,r,c] = preds[:,:,i] \n",
    "        if r == c:\n",
    "            L[:,:,r,c] = F.softplus(L[:,:,r,c])\n",
    "        i+=1\n",
    "\n",
    "covars = L @ L.transpose(2,3)\n",
    "print(covars)\n",
    "# # print(L)\n",
    "# print(covars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussprot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
